{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>PA4 - 40 pts</h2>\n",
    "<h3>Change this filename to \"YourLastName_PA4\"</h3>\n",
    "<p>In this programming assignment, we will be practicing using BeautifulSoup to scrape data from the website <a href=\"http://quotes.toscrape.com\">quotes.toscrape.com</a></p>\n",
    "<p><b>Questions 1 through 4</b> will involve scraping the front page of this website. <br/><b>Questions 5 through 7</b> will involve making a request to a page within the site and scraping values from that page.<br/><b>Questions 8 through 10</b> will involve building a web crawler to navigate through a set of pages</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) import the requests module and BeautifulSoup from the bs4 module.\n",
    "# Make a soup object from the \"quotes.toscrape.com\" request content.\n",
    "# Add additional Jupyter Notebook cells as needed.\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "r = requests.get('http://quotes.toscrape.com?')\n",
    "soup = BeautifulSoup(r.text,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      "/login\n",
      "/author/Albert-Einstein\n",
      "/tag/change/page/1/\n",
      "/tag/deep-thoughts/page/1/\n",
      "/tag/thinking/page/1/\n",
      "/tag/world/page/1/\n",
      "/author/J-K-Rowling\n",
      "/tag/abilities/page/1/\n",
      "/tag/choices/page/1/\n",
      "/author/Albert-Einstein\n",
      "/tag/inspirational/page/1/\n",
      "/tag/life/page/1/\n",
      "/tag/live/page/1/\n",
      "/tag/miracle/page/1/\n",
      "/tag/miracles/page/1/\n",
      "/author/Jane-Austen\n",
      "/tag/aliteracy/page/1/\n",
      "/tag/books/page/1/\n",
      "/tag/classic/page/1/\n",
      "/tag/humor/page/1/\n",
      "/author/Marilyn-Monroe\n",
      "/tag/be-yourself/page/1/\n",
      "/tag/inspirational/page/1/\n",
      "/author/Albert-Einstein\n",
      "/tag/adulthood/page/1/\n",
      "/tag/success/page/1/\n",
      "/tag/value/page/1/\n",
      "/author/Andre-Gide\n",
      "/tag/life/page/1/\n",
      "/tag/love/page/1/\n",
      "/author/Thomas-A-Edison\n",
      "/tag/edison/page/1/\n",
      "/tag/failure/page/1/\n",
      "/tag/inspirational/page/1/\n",
      "/tag/paraphrased/page/1/\n",
      "/author/Eleanor-Roosevelt\n",
      "/tag/misattributed-eleanor-roosevelt/page/1/\n",
      "/author/Steve-Martin\n",
      "/tag/humor/page/1/\n",
      "/tag/obvious/page/1/\n",
      "/tag/simile/page/1/\n",
      "/page/2/\n",
      "/tag/love/\n",
      "/tag/inspirational/\n",
      "/tag/life/\n",
      "/tag/humor/\n",
      "/tag/books/\n",
      "/tag/reading/\n",
      "/tag/friendship/\n",
      "/tag/friends/\n",
      "/tag/truth/\n",
      "/tag/simile/\n",
      "https://www.goodreads.com/quotes\n",
      "https://scrapinghub.com\n"
     ]
    }
   ],
   "source": [
    "# (2a) From the soup object, print the 'url' of all links in the page.\n",
    "# hint: print the 'href' content in all 'a' tags\n",
    "\n",
    "results = soup.find_all('a')\n",
    "links = []\n",
    "for child in results:\n",
    "    if child.name == 'a':\n",
    "        print(child['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# (2b) Print the total number of links to an author page from this page.\n",
    "# i.e. how many of the links above are to an authors profile page\n",
    "\n",
    "results = soup.find_all('div', attrs = {'class':'col-md-8'})\n",
    "col_md = results[1]\n",
    "authors = col_md.find_all('small', attrs = {'class':'author'})\n",
    "count = 0\n",
    "for child in authors:\n",
    "    count+=1\n",
    "   \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“A day without sunshine is like, you know, night.”\n"
     ]
    }
   ],
   "source": [
    "# (3) From the soup object, print the quote from Steve Martin\n",
    "\n",
    "results = soup.find_all('span', attrs = {'class':'text'})\n",
    "print(results[-1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['edison', 'failure', 'inspirational', 'paraphrased']\n"
     ]
    }
   ],
   "source": [
    "# (4) From the soup object, print all Subject Tags associated with \n",
    "#     Thomas A. Edison's quote\n",
    "\n",
    "results = soup.find_all('div', attrs = {'class':'quote'})\n",
    "sub_Tags = results[7].find_all('a')\n",
    "\n",
    "links = []\n",
    "for child in sub_Tags:\n",
    "    if child.name == 'a':\n",
    "        links.append(child.text)\n",
    "del links[0]\n",
    "print(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Navigating to other pages within the site</h3>\n",
    "<p>Questions 5 through 7 will require pulling page content from other pages within the quotes.toscrape.com site</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'March 14, 1879'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (5) Scrape and print Albert Einstein's birthdate\n",
    "\n",
    "url = 'http://quotes.toscrape.com/author/Albert-Einstein'\n",
    "\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.text,'html.parser')\n",
    "\n",
    "birth = soup.find('span', attrs = {'class':'author-born-date'})\n",
    "\n",
    "birth.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Steventon Rectory, Hampshire, The United Kingdom'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (6) Scrape and print Jane Austen's place of birth\n",
    "\n",
    "url = 'http://quotes.toscrape.com/author/Jane-Austen/'\n",
    "\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.text,'html.parser')\n",
    "\n",
    "birth_place = soup.find('span', attrs = {'class':'author-born-location'})\n",
    "\n",
    "birth_place.text[3::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“The reason I talk to myself is because I’m the only one whose answers I accept.”\n",
      "“A lie can travel half way around the world while the truth is putting on its shoes.”\n",
      "“The truth.\" Dumbledore sighed. \"It is a beautiful and terrible thing, and should therefore be treated with great caution.”\n",
      "“Never tell the truth to people who are not worthy of it.”\n"
     ]
    }
   ],
   "source": [
    "# (7) Print all quotes with the Subject Tag: 'truth'\n",
    "\n",
    "url = 'http://quotes.toscrape.com/tag/truth/'\n",
    "\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.text,'html.parser')\n",
    "\n",
    "search = soup.find_all('div',attrs = {'class':'col-md-8'})\n",
    "results = search[1]\n",
    "\n",
    "tag = results.find_all('span',attrs = {'class':'text'})\n",
    "for i in tag:\n",
    "    print(i.text)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Web crawling to extract larger data sets</h3>\n",
    "<p>Questions 8 through 10 will require building a web crawling algorithm to traverse the website to extract data</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['André Gide', 'Marilyn Monroe', 'Bob Marley', 'Elie Wiesel', 'Friedrich Nietzsche', 'Pablo Neruda', 'James Baldwin', 'Jane Austen', 'C.S. Lewis', 'Alfred Tennyson', 'J.M. Barrie']\n"
     ]
    }
   ],
   "source": [
    "# (8) Print a list of all author's names who have a quote with\n",
    "#     the Subject Tag \"love\"\n",
    "#     Note: each author's name should only print once.\n",
    "\n",
    "baseurl = 'http://quotes.toscrape.com'\n",
    "\n",
    "url = 'http://quotes.toscrape.com/tag/love/page/1/'\n",
    "\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.text,'html.parser')\n",
    "\n",
    "\n",
    "\n",
    "link = soup.find('li', attrs = {'class':'next'})\n",
    "nxt_link = link.a['href']\n",
    "check = soup.find('ul')\n",
    "crawl = True\n",
    "\n",
    "a = []\n",
    "\n",
    "while crawl == True:\n",
    "   \n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content,'html.parser')\n",
    "    \n",
    "    authors = soup.find_all('small',attrs = {'class':'author'})    \n",
    "    \n",
    "    for i in authors:\n",
    "        a.append(i.text)    \n",
    "        \n",
    "    nxt_Tag = soup.find('li', {'class':'next'})\n",
    "    \n",
    "    if nxt_Tag:\n",
    "        # Note: starting on page 2, the href format changed, so we\n",
    "        # need to modify our base url to reflect this change...\n",
    "        url = baseurl + nxt_Tag.a['href']\n",
    "    else:\n",
    "        crawl = False    \n",
    "   \n",
    "authors = list(dict.fromkeys(a)) \n",
    "print(authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“Good friends, good books, and a sleepy conscience: this is the ideal life.”\n",
      "“I have never let my schooling interfere with my education.”\n",
      "“′Classic′ - a book which people praise and don't read.”\n",
      "“The fear of death follows from the fear of life. A man who lives fully is prepared to die at any time.”\n",
      "“A lie can travel half way around the world while the truth is putting on its shoes.”\n",
      "“Never tell the truth to people who are not worthy of it.”\n"
     ]
    }
   ],
   "source": [
    "# (9) Print all quotes by Mark Twain found on this site. \n",
    "#     (not just the front page)\n",
    "\n",
    "url = 'http://quotes.toscrape.com/page/1/'\n",
    "r = requests.get('http://quotes.toscrape.com/page/1/')\n",
    "soup = BeautifulSoup(r.text,'html.parser')\n",
    "  \n",
    "crawl = True\n",
    "\n",
    "while crawl == True:\n",
    "   \n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content,'html.parser')       \n",
    "    \n",
    "    results = soup.find_all('small',attrs = {'class':'author'})\n",
    "    quote = soup.find_all('div',attrs = {'class':'quote'})\n",
    "    \n",
    "    count = 0\n",
    "    for i in quote:    \n",
    "        if i.small.text == 'Mark Twain':\n",
    "            index = count            \n",
    "            print(quote[index]('span')[0].text)            \n",
    "        count+=1\n",
    "    nxt_Tag = soup.find('li', {'class':'next'})\n",
    "    \n",
    "    \n",
    "    if nxt_Tag:\n",
    "        # Note: starting on page 2, the href format changed, so we\n",
    "        # need to modify our base url to reflect this change...                \n",
    "        url = baseurl + nxt_Tag.a['href']            \n",
    "    else:\n",
    "        crawl = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a search term: future\n",
      "No matches found.\n"
     ]
    }
   ],
   "source": [
    "# (10) Prompt the user to enter in a search term.  Then print each\n",
    "#      author and quote for any quotes that contain this search term.\n",
    "#      If no quotes are found that contain the search term, \n",
    "#      print \"No matches found\".\n",
    "#      Test results: There are 9 quotes containing 'book'\n",
    "#                    There are 0 quotes containing 'future'\n",
    "\n",
    "url = 'http://quotes.toscrape.com/page/1/'\n",
    "r = requests.get('http://quotes.toscrape.com/page/1/')\n",
    "soup = BeautifulSoup(r.text,'html.parser')\n",
    "  \n",
    "bbreak = False\n",
    "match = False\n",
    "\n",
    "search = input(\"Enter a search term: \")\n",
    "\n",
    "crawl = True\n",
    "\n",
    "while crawl == True:\n",
    "   \n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content,'html.parser')     \n",
    "    \n",
    "    results = soup.find_all('small',attrs = {'class':'author'})\n",
    "    quote = soup.find_all('div',attrs = {'class':'quote'}) \n",
    "\n",
    "    count = 0\n",
    "    for i in quote:    \n",
    "        if search in i('span')[0].text:                                               \n",
    "            print('------------------------------------------')\n",
    "            print('Author: ' + i.small.text)\n",
    "                       \n",
    "            print('Quote: ' + i.span.text)\n",
    "            \n",
    "            print('------------------------------------------')\n",
    "            match = True\n",
    "        else:\n",
    "            sbreak = True          \n",
    "    \n",
    "    nxt_Tag = soup.find('li', {'class':'next'})\n",
    "    \n",
    "    if nxt_Tag:\n",
    "        # Note: starting on page 2, the href format changed, so we\n",
    "        # need to modify our base url to reflect this change...                \n",
    "        url = baseurl + nxt_Tag.a['href']\n",
    "    else: crawl = False\n",
    "    \n",
    "    \n",
    "if(sbreak == True and match != True):\n",
    "    print('No matches found.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
